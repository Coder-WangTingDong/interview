# 基础知识

### 一、零散知识点

##### 问题

###### 数据幂等的处理

```

```

###### 什么是序列化、反序列化？什么场景用

```

```

###### 重写、重载

###### char是否可以存储一个汉字

###### 异常

```
1. 异常用来干嘛？
	也是一种代码分支的实现方式
```



### 二、集合

#### Collection

#####  List

###### Vector(已废弃)

![image-20220217102444335](C:\Users\Administrator\Desktop\interview\vector.png)

```java
0. 底层数据结构是"数组"
1. 成员变量
    protected Object[] elementData;
	protected int elementCount;
	// 数组长度增加的变量值
	protected int capacityIncrement;
	// 默写虚拟机将header words也保存在数据中，所以-8
	private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
2. 构造方法
    // 无参，默认长度为10
    public Vector() {
        this(10);
    }
	// 有参
    public Vector(int initialCapacity) {
        this(initialCapacity, 0);
    }
    public Vector(int initialCapacity, int capacityIncrement) {
        super();
        if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal Capacity: "+
                                               initialCapacity);
        this.elementData = new Object[initialCapacity];
        this.capacityIncrement = capacityIncrement;
    }
3. 添加
    // 增加synchronized，保证线程安全，同时会降低效率
    public synchronized boolean add(E e) {
        modCount++;
        ensureCapacityHelper(elementCount + 1);
        elementData[elementCount++] = e;
        return true;
    }
	// 扩容：新数组的扩容长度为原数组的两倍
	private void grow(int minCapacity) {
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + ((capacityIncrement > 0) ? capacityIncrement : oldCapacity);
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        elementData = Arrays.copyOf(elementData, newCapacity);
    }

```

###### ArrayList

![image-20220217102052215](C:\Users\Administrator\Desktop\interview\ArrayList.png)

```java
0. 底层数据结构是"数组"
1. 集合的成员变量
    private static final int DEFAULT_CAPACITY = 10;
    private static final Object[] EMPTY_ELEMENTDATA = {};
    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};
    transient Object[] elementData;// 禁止该变量被序列化 
    private int size;
	protected transient int modCount = 0;
    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
2. 构造方法
    // 无参构造方法，默认赋值为{},添加元素的默认长度则为10
    public ArrayList() {
        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
    }
	// 有参构造
    public ArrayList(int initialCapacity) {
        if (initialCapacity > 0) {
            this.elementData = new Object[initialCapacity];
        } else if (initialCapacity == 0) {
            this.elementData = EMPTY_ELEMENTDATA;// EMPTY_ELEMENTDATA={}
        } else {
            throw new IllegalArgumentException("Illegal Capacity: " + initialCapacity);
        }
    }
3. 添加元素
    public boolean add(E e) {
    	// 确定集合中的数组
        ensureCapacityInternal(size + 1);
    	// 给对应的数组下标赋值，且size+1
        elementData[size++] = e;
        return true;
    }
    private void ensureCapacityInternal(int minCapacity) {
        ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
    }
	// 计算数组容量
    private static int calculateCapacity(Object[] elementData, int minCapacity) {
        // 如果集中的元素为空，集合长度取默认长度与传递值的最大值
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            return Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        // 集合中的元素不为空，则容量取传递值
        return minCapacity;
    }
	// 设置数组容量
    private void ensureExplicitCapacity(int minCapacity) {
        modCount++;
        // 如果传递的数组长度>集合现有长度，则扩容
        if (minCapacity - elementData.length > 0)
            grow(minCapacity);
    }
	// 数组扩容
    private void grow(int minCapacity) { 
        int oldCapacity = elementData.length;
        // 新数组的长度为老数组长度的1.5倍
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        // 如果扩容1.5倍后的长度 > 传递的数组长度，则使用传递的值
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        // 当新数组的长度 > Integer.MAX_VALUE - 8, 则扩容
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // 将原数组的值赋值到新的数组中，并指向新的数组
        elementData = Arrays.copyOf(elementData, newCapacity);
    }
```

###### LinkedList

![image-20220217105837260](C:\Users\Administrator\Desktop\interview\LinkedList.png)

```java
0. 底层数据结构是"双向链表"
1. 内部类(Node:保存节点信息)
    private static class Node<E> {
        E item;// value
        Node<E> next;// 前一个节点
        Node<E> prev;// 后一个节点
        Node(Node<E> prev, E element, Node<E> next) {
            this.item = element;
            this.next = next;
            this.prev = prev;
        }
    }
2. 成员变量
    transient int size = 0;
    transient Node<E> first;// 头节点
    transient Node<E> last;// 尾节点
3. 构造方法
    // 无参
    public LinkedList() {
    } 
	// 有参
    public LinkedList(Collection<? extends E> c) {
        this();
        addAll(c);
    }
4. 添加
    public boolean add(E e) {
        linkLast(e);
        return true;
    }
	// 默认为尾插
    void linkLast(E e) {
        final Node<E> l = last;
        final Node<E> newNode = new Node<>(l, e, null);
        last = newNode;
        if (l == null)
            first = newNode;
        else
            l.next = newNode;
        size++;
        modCount++;
    }
	// 头插
    private void linkFirst(E e) {
        final Node<E> f = first;
        final Node<E> newNode = new Node<>(null, e, f);
        first = newNode;
        if (f == null)
            last = newNode;
        else
            f.prev = newNode;
        size++;
        modCount++;
    }

```

##### Set

###### HashSet

![image-20220218105848086](C:\Users\Administrator\Desktop\interview\HashSet.png)

```java
0. 底层结构"哈希表"
1. 成员变量
    private transient HashMap<E,Object> map;
    private static final Object PRESENT = new Object();
2. 构造函数
    public HashSet() {
        map = new HashMap<>();
    } 
    public HashSet(Collection<? extends E> c) {
        map = new HashMap<>(Math.max((int) (c.size()/.75f) + 1, 16));
        addAll(c);
    } 
    public HashSet(int initialCapacity, float loadFactor) {
        map = new HashMap<>(initialCapacity, loadFactor);
    } 
    public HashSet(int initialCapacity) {
        map = new HashMap<>(initialCapacity);
    }
```



#### Map

###### Hashtable

###### HashMap

![image-20220218143210679](C:\Users\Administrator\Desktop\interview\HashMap.png)

```java
0. 底层结构"哈希表"
1. 内部类
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;

        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }

        public final K getKey()        { return key; }
        public final V getValue()      { return value; }
        public final String toString() { return key + "=" + value; }

        public final int hashCode() {
            return Objects.hashCode(key) ^ Objects.hashCode(value);
        }

        public final V setValue(V newValue) {
            V oldValue = value;
            value = newValue;
            return oldValue;
        }

        public final boolean equals(Object o) {
            if (o == this)
                return true;
            if (o instanceof Map.Entry) {
                Map.Entry<?,?> e = (Map.Entry<?,?>)o;
                if (Objects.equals(key, e.getKey()) &&
                    Objects.equals(value, e.getValue()))
                    return true;
            }
            return false;
        }
    }
2. 成员变量
3. 添加
    public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
    
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```

###### ConcurrentHashMap

##### 队列

###### Queue：队列

###### Deque：双端队列

### 三、多线程与并发

##### 面试问题

###### 如何预防死锁

1. 死锁发生的必要条件

   * 互斥：同一时间只能有一个线程获取资源(无法破坏)
   * 不可剥夺：一个线程已经占有的资源，在释放前不会被其他线程抢占
   * 请求和保持：线程等待过程中不会释放已占有的资源
   * 循环等待：多个线程互相等待对方释放资源

2. 破坏

   * 资源互斥是固有特性，无法改变

   * 破坏不可剥夺

     一个进程不能获得所需的全部资源便处于等待状态，等待期间他占有的资源将被隐式的释放重新加入到系统的资源列表中

   * 破坏请求和保持

     * 静态分配：每个进程在开始执行时，就申请他所需要的全部资源
     * 动态分配：每个进程在申请所需资源时，本身不占用系统资源(银行家算法)

   * 破坏循环等待

     采用资源有序分配：将资源进行编号，紧缺的采用较大的编号，申请资源时必须按照编号来，一个进程只有获得较小的编号才能申请较大编号的进程

###### 线程的创建方式

* 实现Runnable接口，无返回值，无法抛出异常
* 实现Callable接口，有返回值，可以抛出异常
* 继承Thread类，重写run()方法，调用start()执行
* 通过线程池创建线程

###### 线程安全活跃态问题、竞态条件

1. 线程安全的活跃性问题分为：死锁、活锁、饥饿

###### Java中的wait和sleep的区别和联系

1. 所属类：wait是Object方法；sleep是Thread方法
2. 作用范围：sleep方法没有释放锁，只是休眠；wait方法释放了锁，使得其他线程可以使用同步控制块或方法
3. 使用范围：wait只能在同步方法或同步快里面执行；sleep可以在任何地方使用

###### CPU与线程池数量

CPU密集型：N+1

I/O密集型：2N+1

###### notify和notifyAll区别

###### synchronized和lock区别

###### 多线程之间是如何通信的



##### 概念

###### 三大特性

* **原子性**

  提供了互斥访问，同一时刻只能有一个线程对它进行操作

  ```java
  1. 提供了互斥访问，同一时刻只能有一个线程对它进行操作
  2. Atomic包
  	2.1 AtomicXXX：CAS、Unsafe.compareAndSwapInt
      	// var1调用的对象，var2原始值的偏移量，var4增加量
          public final int getAndAddInt(Object var1, long var2, int var4) {
          	// 记录从内存中获取的值，也是期望值
              int var5;
              do {
              	// 根据偏移量从内存中获取object的值
                  var5 = this.getIntVolatile(var1, var2);
                  // 根据偏移量从内存中获取object的值,与期望值进行比较,如果相同将内存中的值更新为新值,返回true,否则循环执行,直到期望值与内存中的值一致
              } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
              return var5;
          }
          // var1-需要更新的对象,var2-obj中整型field的偏移量,var4-希望field中存在的值,var5-如果期望值expect与field的当前值相同，设置filed的值为这个新值,如果field的值被更改返回true
          public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);
  		// 如果和期望值一样则更新为更新值
  		public final boolean compareAndSet(int expect, int update) {
          	return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
      	}
  		2.1.1 Q1：循环时间长：当期内存中的值与期望值不一致时，会自旋CAS操作，如果长时间不成功，会增加CPU的执行开销
          2.1.2 Q2：ABA问题：CAS在操作值的时候检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。
          	  A2：ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A
               【注】从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相	   等，则以原子方式将该引用和该标志的值设置为给定的更新值。
          2.1.3 Q3：只能保证一个共享变量的原子操作
          	  A3：从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作
  	2.2 AtomicLong和LongAdder(JDK8)
          CAS操作是在一个死循环中进行，如果竞争不激烈时，修改成功的概率很高，否则失败概率很高，大量修改失败时，就会进行多次的循环操作，影响性能。
          对于普通类型变量long和double，jvm允许将64位读操作或写操作分成32位的操作。
          "LongAdder类的核心是将热点数据分离，比如将AtomicLong的value分离成数组，每个线程访问时，通过hash等算法映射到其中一个数字计数，而最终计数结果为这个数组的求和累加。" -- 没懂
          线程竞争低适于用AtomicLong
      2.3 AtomicReference和AtomicReferenceFieldUpdater
  3. 锁
  	3.1 synchronized：依赖jvm
      	* 修饰代码块：大括号括起来的代码，作用于调用的对象
          	public void test(){
              	synchronized(this){
                  	...
                  }
              }
              this：调用该方法的对象
          * 修饰方法：整个方法，作用于调用的对象
          	public synchronized void test(){
              	...
              }
              子类继承父类，synchronized是不会被继承的
          * 修饰静态方法：整个静态方法，作用于所有对象
          	public static synchronized void test(){
              	...
              }
          * 修饰类：括号括起来的部分，作用于所有对象
          	public void test(){
              	synchronized(类名.class){
                  	...
                  }
              }
      3.2 Lock：依赖特殊的CPU指令，代码实现(如：ReentrantLock)
      3.3 对比
      	synchronized：不可中断锁，适合竞争不激烈，可读性好
          Lock：可中断锁，多样化同步，竞争激烈能维持常态
          Atomic：竞争激烈时能维持常态，比Lock性能好；只能同步一个值
  ```

* **可见性**

  ```java
  1. 一个线程对主内存的修改可以及时的被其他线程观察到
  2. 导致共享变量在线程间不可见的原因
  	 * 线程交叉执行
  	 * 重排序结合线程交叉执行
  	 * 共享变量更新后的值没有在工作内存与主存间及时更新
  3. JMM关于synchronized的规定
  	 * 线程解锁前，必须把共享变量的最新值刷新到主内存
  	 * 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存重新读取最新的值(加锁与解锁是同一把锁)
  4. volatile
       * 使变量在多个线程间可见
  	 * 通过"内存屏障"和"禁止重排序"优化来实现
     	 	1> 对volatile变量写操作时，会在写操作后加一条store屏障指令，将本地内存中的共享变量值刷新到主内存
  		2> 对volatile变量读操作时，会在读操作前加一条load屏障指令，从主内存中读取共享变量
     	 * volatile读写
  		 1> 普通读 -> 普通写 -> StoreStore屏障 -> volatile写 -> StoreLoad屏障
  		 	  StoreStore屏障：禁止普通写和volatile写重排序
       	  	  StoreLoad屏障：防止volatile写和后续可能有的volatile写/读重排序
  	   	 2> volatile读 -> LoadLoad屏障 -> LoadStore屏障 -> 普通读 -> 普通写
  			  LoadLoad屏障：禁止下面所有的普通读操作和前面的volatile读重排序
          	  LoadStore屏障：禁止下面所有的写操作和前面的volatile读重排序
      【注】i++不是原子操作(取值i;i+1;i刷新到主存)，所以volatile修饰的变量自增是线程不安全的，即volatile不具备原子性
  5. 适用场景
  	 具备的条件：对变量的写操作不依赖于当前值；该变量没有包含在具有其他变量的不变的式子中
  ```

* **有序性**

  ```
  1. 一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般杂乱无序
  2. Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程中不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性
  3. volatile、synchronized、Lock等保证有序性
  4. happens-before原则
     * 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
     * 锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作
     * volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作
     * 传递规则：操作A先行发生于B，而B又先行发生于C，则可以得出A先行于C
     * 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作
     * 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
     * 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
     * 对象终结规则：一个对象的初始化完成先行于他的finalize()方法的开始
  ```

###### 对象发布和对象溢出

```
1. 对象发布：使一个对象能够被当前范围之外的代码所使用
2. 对象溢出：一种错误的发布，当一个对象还没有被构造完成时，就使它被其他线程所见
3. 安全发布对象
	3.1 在静态初始化函数中初始化一个对象引用
	3.2 将对象的引用保存到volatile类型或AtominReference对象中
	3.3 将对象的引用保存到某个正确构造对象的final类型域中
	3.4 将对象的引用保存到一个由锁保护的域中
```

##### 线程池

###### 参数

```java
public ThreadPoolExecutor(
    int corePoolSize,// 核心线程数量大小   
    int maximumPoolSize,// 线程池最大容纳线程数，当达到这个数值，根据拒绝策略进行处理
    long keepAliveTime,// 非核心线程闲置时的超时时长
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,//缓存异步任务的队列
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler// 线程池任务满载后采取的任务拒绝策略 
)
```

###### 工作原则

```
1、当线程池中线程数量小于 corePoolSize 则创建线程，并处理请求。
2、当线程池中线程数量大于等于 corePoolSize 时，则把请求放入 workQueue 中,随着线程池中的核心线程们不断执行任务，只要线程池中有空闲的核心线程，线程池就从 workQueue 中取任务并处理。
3、当 workQueue 已存满，放不下新任务时则新建非核心线程入池，并处理请求直到线程数目达到 maximumPoolSize（最大线程数量设置值）。
4、如果线程池中线程数大于 maximumPoolSize 则使用 RejectedExecutionHandler 来进行任务拒绝处理。
```

##### J.U.C(包名:java.util.concurrent)

JUC用于解决多线程同步问题，给Java开发者提供便利的函数、功能和结构等。

### 四、I\O、网络

### 五、设计模式

##### 策略模式

###### 原因

重构调度功能时，由于枚举值(场景线路数需要计算同一个引擎不会超过该引擎设置的最大值、引擎线路数：所有引擎线路数之和不能超过最大线路数、通用值)的设定具有不同的逻辑，写在同一个类中，需要多重条件判断，可读性差。

###### 设计

```
1.定义一个接口，其中一个抽象方法，参数是业务类型
2.不同的实现类实现该接口，重写抽象方法
3.注入到业务类，进行使用
```

###### 代码

```java
public interface IDictHandler {  
    // 根据传递参数判断选择哪个实现类
    Map<String, Object> handleDictInfoByLinkParam(String operate, String linkParam, DictEntity dictEntity);
}

/* 具体业务类*/
// 注入
@Autowired
private List<IDictHandler> listHandlerChain;
或
@Autowired
private Map<String, IDictHandler> mapHandler;
// 遍历实现类
for (IDictHandler handlerChain : listHandlerChain) {
    Map<String, Object> map = handlerChain.handleDictInfoByLinkParam(operation, "null".equals(linkParam) ? null : linkParam, dictEntity);
    if (MapUtils.isEmpty(map)) {
        continue;
    }
    Integer code = (Integer) map.get("code");
    if(code == 500){
        redisTemplate.discard();
        throw new RuntimeException(String.valueOf(map.get("msg")));
    }
    break;
} 

/*接口实现类:继承接口，具体实现类实现各自的逻辑*/
public class StrategyDictImplHandler implements IDictHandler {
    @Override
    public Map<String, Object> handleDictInfoByLinkParam(String operate, String linkParam, DictEntity dictEntity) {
         ...
    }
}
public class EngineLineDictImplHandler implements IDictHandler {}
...
```

##### 模板模式

###### 原因

```
项目"接收原始数据(从ftp读取文件)"在不同的服务间基本一样，起初为了项目进度，没有进行过度设计，后期随着业务场景的增多，这些功能在代码中凸显的很冗余，增加一个功能逻辑，需要所有服务都要重写，不易扩展，所以重构项目的同时对这两部分功能使用"模板模式"进行重构
```

###### 设计

```java
1. 接收原始数据(在接口中定义模板方法，模板方法中通用的功能，在接口中定义default方法，如果需要扩展的重写default方法)
    default int batchReceive() {
    /* 1.获取校验通过的文件名称*/
    List<String> listName = listName();
    if(CollectionUtils.isEmpty(listName)){
        closeSftpStream();
        return 0;
    }
    /* 2.自定义解析前的操作：比如按照文件名排序...*/
    List<String> customBeforeList = customOperationForAnalysisBefore(listName);
    if(CollectionUtils.isEmpty(customBeforeList)){
        closeSftpStream();
        return 0;
    }
    /* 3.解析文件*/
    List<Long> headIdList = analysis(customBeforeList);
    if(CollectionUtils.isEmpty(headIdList)){
        closeSftpStream();
        return 0;
    }
    /* 4.解析完成后的校验：比如文件数量的比对...*/
    List<Long> checkoutHeadIdList = checkoutForAnalysisAfter(headIdList);
    if(CollectionUtils.isEmpty(checkoutHeadIdList)){
        closeSftpStream();
        return 0;
    }
    /* 5.关闭流*/
    closeSftpStream();
    /* 6.自定解析完成后的操作*/
    List<Long> customAfterList = customOperationForAnalysisAfter(checkoutHeadIdList);
    if(CollectionUtils.isEmpty(customAfterList)){
        return 0;
    }
    /* 7.将数据添加到taskpool中*/
    return insertTaskPool(customAfterList);
}
2. 使用抽象类实现此接口，添加默认实现(接口也可以定义，但是感觉可读性不好)，因为实现类必须要实现方法，防止不需要的也要实现
3. 不同的业务场景继承抽象类，根据需要重写需要的方法
```

##### 代理模式

###### 动态代理

* JDK代理：基于反射机制

  ![img](C:\Users\Administrator\Desktop\interview\JDK代理)

  ```
  利用拦截器(拦截器必须实现InvocationHanlder)加上反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。是在程序运行的过程中，根据被代理的接口来动态生成代理类的class文件，并加载运行的过程
  1.InvocationHanlder
  	Object invoke(Object proxy, Method method, Object[] args) throws Throwable
  		proxy:指代JDK动态生成的最终代理对象 
  		method:指代的是我们所要调用真实对象的某个方法的Method对象 
  		args:指代的是调用真实对象某个方法时接受的参数
  2.Proxy
  	Proxy这个类的作用就是用来动态创建一个代理对象的类，它提供了许多的方法，但是我们用的最多的就是newProxyInstance这个方法
  	public static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces,  InvocationHandler handler)  throws IllegalArgumentException
  		loader:ClassLoader对象，定义了由哪个ClassLoader来对生成的代理对象进行加载。
  		interfaces:Interface对象的数组，表示的是我将要给我需要代理的对象提供一组什么接口，如果我提供了一组接口给它，那么这个代理对象就宣称实现了该接口(多态)，这样我就能调用这组接口中的方法了。
  		Handler：InvocationHandler对象，表示的是当我这个动态代理对象在调用方法的时候，会关联到哪一个InvocationHandler对象上。
  3.样例
    // 创建接口类
    public interface HelloInterface {
    	void sayHello();
    }     
    // 创建被代理类，实现接口
    public class HelloImpl implements HelloInterface{
        @Override
        public void sayHello() {
        	System.out.println("hello");
        }
    }
    // 创建拦截器
    public class ProxyHandler implements InvocationHandler{
          private Object subject; // 这个就是我们要代理的真实对象，也就是真正执行业务逻辑的类
          public ProxyHandler(Object subject) {// 通过构造方法传入这个被代理对象
              this.subject = subject;
          }
          @Override
          public Object invoke(Object obj, Method method, Object[] objs)
                  throws Throwable {
              Object result = null;
              System.out.println("可以在调用实际方法前做一些事情");
              System.out.println("当前调用的方法是" + method.getName());
              result = method.invoke(subject, objs);// 需要指定被代理对象和传入参数
              System.out.println(method.getName() + "方法的返回值是" + result);
              System.out.println("可以在调用实际方法后做一些事情");
              System.out.println("------------------------");
              return result;// 返回method方法执行后的返回值
          }
  	}
    // 测试方法
    public class Mytest {
      	public static void main(String[] args) {
              //第一步：创建被代理对象
              HelloImpl hello = new HelloImpl();
              //第二步：创建handler,传入真实对象
              ProxyHandler handler = new ProxyHandler(hello);
              //第三步：创建代理对象，传入类加载器、接口、handler
              HelloInterface helloProxy = (HelloInterface) Proxy.newProxyInstance(
                      HelloInterface.class.getClassLoader(), 
                      new Class[]{HelloInterface.class}, handler);
              //第四步：调用方法
              helloProxy.sayHello();
      	}
    	}
              
  ```

  



### 六、JVM

##### 知识点

###### 为什么基本类型不放在堆中

```
因为其占用的空间一般是1~8个字节——需要空间比较少，而且因为是基本类型，所以不会出现动态增长的情况——长度固定，因此栈中存储就够了，如果把他存在堆中是没有什么意义的。可以这么说，基本类型和对象的引用都是存放在栈中，而且都是几个字节的一个数，因此在程序运行时，他们的处理方式是统一的。但是基本类型、对象引用和对象本身就有所区别了，因为一个是栈中的数据一个是堆中的数据。最常见的一个问题就是，Java中参数传递时的问题。
```

###### 堆和栈存放的数据

```
堆中存的是对象。栈中存的是基本数据类型和堆中对象的引用。一个对象的大小是不可估计的，或者说是可以动态变化的，但是在栈中，一个对象只对应了一个4btye的引用
```

###### new对象如果已经被加载过，JVM如何创建新的对象，保证地址不一样(省了类加载的哪一步)

##### 对象的创建

.java -javac-> .class -类加载、JIT/字节码解释器-> 执行引擎

###### 类加载

* **Loading：通过ClassLoader加载字节码，生成class对象(懒加载)**

  ```
  1.加载方式
  	1.1显示加载：通过直接调用class.forName()把所需的类加载到JVM
  	1.2隐式加载：程序在使用new等方式创建对象时，会隐式调用类的加载器把对应的类加载到JVM
  2.类加载器
  	BootstrapClassLoader：加载核心库
  	ExtClassLoader：加载扩展类
  	AppClassLoader：加载程序应用类，classpath指定的目录或jar中类
  	CustomClassLoader：自定义
  3.双亲委派机制
  	
  ```

* **linking**

* **初始化**

##### 运行时数据区域

###### 程序计数器

每个线程都有自己的程序计数器，记录线程运行的当前位置

###### 虚拟机栈

存放的是栈帧(每个线程是一个栈，每个方法对应一个栈帧)

栈帧

```
1. 局部变量表
2. 操作数栈
3. 动态链接
4. 返回地址
```

###### 本地方法栈

###### 堆

```
1. 运行时常量池
	class文件中的静态常量池被加载到JVM中而形成"运行时常量池"
2. 对象实例
3. 字符串常量池
4. 线程分配缓冲区
```

###### 方法区

```
0. JDK7永久代是方法区的实现；JDK8元空间是方法区的实现。
1. 存放的数据
	虚拟机加载的类信息、常量、静态变量，即时编译器编译后的代码等
```

* Orika转换Bean导致元空间OOM

  ```
  原因：Orika的类映射是生成字节码文件，该文件是存到元空间中的，直到占满设置的元空间大小，导致内存溢出。
  解决方案：将对象映射的方法放在静态代码块中，只执行一次即可。
  ```

###### ThreadLocal



### 七、SQL

##### 基础

###### 概念

```
1. 全表扫描(FTS)：full table scan
```

###### char、varchar和text区别

```
char:定长，若保存的值长度不够用空格补齐，最多能存储255个字符
varchar:可变长度，若不指定长度，则默认固定长度，最大空间是65535(MySQL5.0.3以前版本varchar(n)中的n表示字节数;MySQL5.0.3以后版本varchar(n)中的n表示字符数)
text:不设置长度，当不知道属性的最大长度时，适合用text

查询速度： char最快， varchar次之，text最慢
```

###### union和union all区别

```
1.union取并集，去除重复行;union all不合并行
2.union按默认规则排序;union all不排序
```

###### 什么情况下索引失效，如何解决

```
1.条件带or，即使部分条件带索引也不会使用 --> 尽量少用or
	要想使用or，则条件中的每个列都加索引
2.复合索引未使用左列字段(最左前缀原则)
3.like查询以"%"开头
4.存在索引列的数据类型隐形转换，则用不上索引
	比如age使用的是varchar类型，查询未使用''
5.where子句里对索引列上有数学运算，用不上索引
6.where 子句里对有索引列使用函数，用不上索引
```

###### 什么情况下不要使用索引

```
1.数据唯一性差（一个字段的取值只有几种时）的字段不要使用索引
	比如性别，只有两种可能数据。意味着索引的二叉树级别少，多是平级。这样的二叉树查找无异于全表扫描。
2.频繁更新的字段不要使用索引
	频繁变化导致索引也频繁变化，增大数据库工作量，降低效率。
3.字段不在where语句出现时不要添加索引,如果where后含IS NULL /IS NOT NULL/ like ‘%输入符%’等条件，不建议使用索引
4.where子句里对索引列使用不等于，使用索引效果一般
```

###### truncate、drop、delete区别;delete在数据量大的情况下删除慢，如何解决

```
1.delete语句执行删除是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中以便进行回滚。
  delete操作不会减少表或索引所占用的空间
  1.1 delete删除慢
  	先根据条件将不需要的数据插入备份表，然后执行truncate，再将数据insert到原始表
2.truncate一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快
  truncate操作后表和索引所占用的空间会恢复到初始大小
3.truncate、drop是DLL（data define language),操作立即生效,原数据不放到rollback segment中,不能回滚
```

##### 事务

###### 事务特性(ACID)

* 原子性：强调事务的不可分割
* 一致性：事务执行的前后数据的完整性保持一致
* 隔离性：一个事务的执行过程中，不应该收到其他事务的干扰
* 持久性：事务一旦结束，数据就会持久到DB

###### 安全性问题

* 脏读：一个事务读到另一个事务的未提交数据
* 不可重复度：一个事务读到另一事务已经提交的update的数据导致多次查询结果不一致
* 幻读：一个事务读到另一个事务已经提交的insert的数据导致多次查询结果不一致

###### 事务隔离级别

* 未提交读：脏读、不可重复度、幻读都可能发生
* 已提交读(Oracle)：避免了脏读
* 可重复读(Mysql)：避免了脏读和不可重复读
* 串行化

##### DB

###### 索引模型

* **哈希表**

  适用于只有等值查询的场景，比如：Memchched及其他NoSql引擎

* **数组**

  有序数组在等值查询和范围查询场景性能比较优秀，只适用于静态存储引擎

* **二叉树**

###### 存储引擎

* **InnoDB**

  ```
  在InnoDB中，表是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。
  每一个索引在InnoDB中对应一颗B+树
  ```

  * 索引模型

    * 主键索引

      **主键索引的叶子节点存的是整行数据**。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）

    * 非主键索引

      **非主键索引的叶子节点内容是主键的值**。在 InnoDB 里，非主键索引也被称为二级索引

    * 回表

      普通索引查询方式：需要先搜索普通索引树，得到主键的值，再到主键索引树搜索一次，这个过程称为回表。

    * 覆盖索引

      查询的值已经在索引上，不需要回表，则称索引为覆盖索引

      由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段

  * 索引维护

    B+树为了维护索引有序性，在插入新值需要做必要的维护。

    **会出现的问题**

    * 如果插入的值比较小，逻辑上需要挪动数据的位置
    * 如果插入值的数据页被占满，则需要新的数据页，然后挪动部分数据到新的数据页，这个过程叫做"页分裂"----影响性能；其次原本一个数据页的数据分到两个数据也，空间利用率降低50%
    * 当相邻两个页由于删除了数据，利用率很低之后，会将数据页合并。

  * **为什么索引使用自增主键**

    ```
    1.性能
    自增主键的数据模式，符合递增插入的场景，每次插入一条新的记录，都是追加操作，不涉及挪动其他记录，也不会触发叶子节点的分裂。而业务逻辑的字段做主键，则不能保证有序插入，导致写数据成本比较高。
    2.存储空间
    由于每个非主键索引的叶子节点都是主键的值。如果使用业务类型字段做主键，那么二级索引的叶子节点占用的空间可能比较大，自增主键的一般用整型做主键，占用4个字节，如果是long类型占用8个字节。
    显然主键长度越小，普通索引的叶子节点就越小，普通索引的占用的空间也就越小
    所以从性能和空间考虑，自增主键往往是合适的选择。
    3.什么场景使用业务主键
    要求：①只有一个索引；②唯一索引
    ```

  * 最左前缀原则

    1. 设计复合索引时，比如(a,b)，则不需要单独为a创建索引

    2. 使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。

  * 索引下推

    在索引遍历的过程中，对索引中包含的字段进行判断，直接过滤不满足条件的记录，减少回表的次数

  * 如果字段前缀有一样的，如何创建索引

    * 倒叙存储

    * 使用hash字段，在表上建立一个整数字段，存储hash值

    * 区别

      1. 空间方法：倒叙是在主键索引，不占用额外空间；hash值需要新建字段
      2. CPU方面：倒叙在读和写都需要额外调用一次函数；而hash字段只需要调用一次
      3. 查询方面：hash值比较稳定，虽然有hash冲突，但是概率很小；倒叙仍然是最左前缀，可能有回表的概率

      

###### 优化

* 使用覆盖索引：减少树的搜索次数，提升查询性能
* 

### 八、数据结构 

### 哈希表(散列表、Hash表)

##### 问题

* Q1：Hash表的数组初始长度是多大

##### 概念

* **散列表**

  散列表用的是数组支持按照下标随机访问数据的特性，所以散列表是数组的一种扩展。

* **键|关键字**

  用作散列的值叫做"键"或"关键字"

* **散列函数(哈希函数、Hash函数)**

  把"键"或"关键字"转化为数组下标的映射方法叫做"散列函数"

* **散列值(哈希值、Hash值)**

  散列函数计算的值叫做"散列值"

* **散列冲突**

  由于不同的key对应的Hash(key)都不一样的散列函数几乎不可能，所以无法避免"散列冲突"。由于数组的存储空间有限，也会将加大散列冲突的概率。

##### 解决散列冲突的方法

* **装载因子(load factor)**

  表示空位的多少

  装载因子=填入表中的元素个数/散列表的长度

  装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降

* **开放寻址法**

  * 核心思想

    如果出现散列冲突，则重新探测一个空闲位置，将其插入。

    * 线性探测

      插入：插入数据时，如果某个数据经过散列函数散列后，位置已被占用，就从当前位置开始，向后查找，是否有空间位置，直到找到为止。

      查找：通过散列函数求出查找元素的键值对应的散列值，比较数组中下标为散列值的元素和要查找的元素，如果相等，则说明就是要找的元素，否则顺序往后查找。如果遍历到数组中的控线位置，还没有找到则说明查找的元素并没在散列表中。

      删除：根据查找规则，如果定位到空闲位置是被删除的元素，那么原来的查找算法失效，本来存在的数据会被认为不存在。(解决方法：将删除的元素特殊标记位deleted，当线性探测查找时，遇到标记位deleted的空间，不停，而是继续往下探测)

      问题：当散列表的数据越来越多，散列冲突的可能性增大，空闲位置越来越少，线性探测的时间会越来越长。

    * 二次探测

      线性探测每次步长是1，那它探测的下标序列是hash(key)+0，hash(key)+1，hash(key)+2...

      二次探测的步长是原来的"二次方"，探测的下标序列是hash(key)+0，hash(key)+1^2，hash(key)+2^2...

    * 双重散列

      不仅使用一个散列函数，而是使用一组散列函数hash(key)，hash2(key)...先使用第一个散列函数，如果计算得到的存储位置已被占用，再使用第二个散列，直到找到空闲的存储位置。

  * 优缺点

    * 优点

      

    * 缺点

* **链表法**

  ![img](C:\Users\Administrator\Desktop\interview\哈希冲突-链表法.jpg)

  插入：插入的时候，通过散列函数计算对应的散列槽位，将其插入到对应链表中即可，时间复杂度为O(1)。

  查找、删除：通过散列删除计算对应的slot，然后遍历链表查找或删除，时间复杂度跟链表的长度成正比。

  * 扩容的缺点

    

# WEB服务

### SpringCloud

#### SpringBoot

###### 启动

* SpringApplication:run()

  ```java
  public ConfigurableApplicationContext run(String... args) {
  	/* 监控*/
  	StopWatch stopWatch = new StopWatch();
  	stopWatch.start();// 开启监控
  	
  	ConfigurableApplicationContext context = null;
  	Collection<SpringBootExceptionReporter> exceptionReporters = new ArrayList();
  	this.configureHeadlessProperty();
      
      /* 监听器：事件监听(工作原理)*/
  	SpringApplicationRunListeners listeners = this.getRunListeners(args);
  	listeners.starting();
  
  	Collection exceptionReporters;
  	try {
  		ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
  		ConfigurableEnvironment environment = this.prepareEnvironment(listeners, applicationArguments);
  		this.configureIgnoreBeanInfo(environment);
  		Banner printedBanner = this.printBanner(environment);
          /* 创建SpringContext容器：AnnotationConfigServletWebServerApplicationContext*/
  		context = this.createApplicationContext();
          /* 加载容器对象:META-INF/spring.factories*/
          // 异常错误报表
  		exceptionReporters = this.getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[]{ConfigurableApplicationContext.class}, context);
          // 上下文准备
  		this.prepareContext(context, environment, listeners, applicationArguments, printedBanner);
  		/* 刷新容器*/
  		this.refreshContext(context);
  		this.afterRefresh(context, applicationArguments);
  		
  		stopWatch.stop();// 停止监控(记录启动时间)
  		if (this.logStartupInfo) {
  			(new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), stopWatch);
  		}
  
  		listeners.started(context);
  		this.callRunners(context, applicationArguments);
  	} catch (Throwable var10) {
  		this.handleRunFailure(context, var10, exceptionReporters, listeners);
  		throw new IllegalStateException(var10);
  	}
  
  	try {
  		listeners.running(context);
  		return context;
  	} catch (Throwable var9) {
  		this.handleRunFailure(context, var9, exceptionReporters, (SpringApplicationRunListeners)null);
  		throw new IllegalStateException(var9);
  	}
  }
  ```

* AbstractApplicationContext:refresh()

  ```java
  public void refresh() throws BeansException, IllegalStateException {
          synchronized(this.startupShutdownMonitor) {
              this.prepareRefresh();
              ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory();
              // 准备bean创建的工厂
              this.prepareBeanFactory(beanFactory);
  
              try {
                  this.postProcessBeanFactory(beanFactory);
                  this.invokeBeanFactoryPostProcessors(beanFactory);
                  this.registerBeanPostProcessors(beanFactory);
                  this.initMessageSource();
                  this.initApplicationEventMulticaster();
                  // 模板方法，不同的spring容器会重写该方法(内置的容器tomcat、jetty...)
                  this.onRefresh();
                  this.registerListeners();
                  this.finishBeanFactoryInitialization(beanFactory);
                  this.finishRefresh();
              } catch (BeansException var9) {
                  if (this.logger.isWarnEnabled()) {
                      this.logger.warn("Exception encountered during context initialization - cancelling refresh attempt: " + var9);
                  }
                  this.destroyBeans();
                  this.cancelRefresh(var9);
                  throw var9;
              } finally {
                  this.resetCommonCaches();
              }
  
          }
    }
  ```

  * **ConfigurationClassParser**

    

#### Zuul

###### 实现动态路由刷新

```java
1. 初始化路由信息(从DB加载)
    public void initRoute(Map<String, ZuulRoute> routesMap, List<Map<String, String>> pathMapping) {
		// 删除路由信息
		if (!MapUtils.isEmpty(routesMap) || !CollectionUtils.isEmpty(pathMapping)) {
			routesMap.clear();
			pathMapping.clear();
		}

		// 从DB中加载路由信息
		List<ConfigGatewayEntity> list = this.selectList(null);
		list.stream().forEach(e -> {
			// 组装route信息
			ZuulRoute zuulRoute = new ZuulRoute();
			String path = e.getPath();
			zuulRoute.setId(e.getKey());
			zuulRoute.setPath(path);
			zuulRoute.setServiceId(e.getServiceId());
			zuulRoute.setStripPrefix("0".equals(e.getStripPrefix()) ? true : false);
			routesMap.put(path, zuulRoute);
			// 组中mapping
			Map<String, String> pathMap = new HashMap<>();
			pathMap.put("source", e.getSource());
			pathMap.put("target", e.getTarget());
			pathMapping.add(pathMap);
		});
	}
2. 刷新路由信息
   public class DynamicRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator {
       public DynamicRouteLocator(String servletPath, ZuulProperties properties) {
           super(servletPath, properties);
       }

       /**
	 	* @Description: RefreshableRouteLocator中的接口
	 	*/
       @Override
       public void refresh() {
           doRefresh();
       }

       /**
	 	* @Description: 覆盖SimpleRouteLocator中的locateRoutes方法，从而实现从DB读路由配置信息
	 	*/
       @Override
       protected Map<String, ZuulRoute> locateRoutes() {
           LinkedHashMap<String, ZuulRoute> routesMap = new LinkedHashMap<>();
           // 继承SimpleRouteLocator中的locateRoutes方法，加载application.yml中的路由配置信息
           routesMap.putAll(super.locateRoutes());
           // 从DB中加载路由信息
           routesMap.putAll(GlobalRouteInfo.routesMap);
           return routesMap;
       }

       /**
	 	* @Description: locateRoutes()protected修饰 无法外部调用
	 	*/
       public void dynamicRefresh(){
           locateRoutes();
       }
	}
3. 动态刷新
    RoutesRefreshedEvent refreshedEvent = new RoutesRefreshedEvent(routeLocator);
	publisher.publishEvent(refreshedEvent);    
```

#### Eureka

###### 自我保护原理

#### Feign

###### 重试策略

* 客户端调用服务端，由于服务端响应超时，客户端重发了一次请求，导致数据重复。

  ```
  原因：当响应超时后，客户端ribbon发起了重试，ribbon都是用默认配置，FeignLoadBalancer中配置了重试相关的策略ribbon.OkToRetryOnAllOperations配置为true,则任何请求方法都进行重试，ribbon.OkToRetryOnAllOperations配置为false时，GET请求方式也会进行重试，非GET方法只有在连接异常时才会进行重试。
  ```

#### Ribbon



### Spring

##### 问题

###### 说一下对Spring的理解

###### Spring为何会自动实例化带有@Controller这些注解的类

###### 实例化的对象若有依赖注入，何时注入？如何避免注入的对象没有实例化(即需要注入的对象还没被实例化)

###### 实例化的对象通过@Autowired、构造方法、set注入的区别

###### 如何解决循环依赖

```
1. 什么是循环依赖
	循环依赖就是循环引用，即两个或两个以上的bean互相持有对象，最终形成闭环。比如A依赖B，B依赖C，C又依赖于A。
2. 三级缓存(3个map)
	2.1 第一级缓存：singletonObjects，主要存放初始化完成后的单例bean
	2.2 第二级缓存：earlySingletonObjects，主要存放经过了实例化，但未初始化的对象
	2.3 第三级缓存：singletonFactories，存放生成bean的工厂，主要存储标记为"正在创建中"的bean
3. 解决方案
	A->B->A
	3.1 创建A发现需要依赖B
	3.2 创建B发现B又依赖A，
	3.3 又创建A，形成闭环，无法停止导致CPU飙升
	3.4 暂停A的初始化，创建B的实例，此时生成A bean的工厂放在第三级缓存中，标记为"创建中"
	3.5 初始化B发现B需要注入A，则B遍历三级缓存，最后在第三级缓存中找到A，提前生成A的aop代理对象，存入第二级缓存，同时移除第三级缓存
	3.6 A的AOP代理的引用注入A，完成B的初始化。(B在初始化过程中已经生成了aop代理-bean初始化正常步骤，初始化完成之后，存入)
	3.7 最后回到A的初始化
```

##### 常用注解

```
@Controller用于标注控制层组件（如struts中的action）
@Service用于标注业务层组件
@Repository用于标注数据访问组件，即DAO组件
@Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。
1.@Component和@Service的区别
    @service引用了@component注解，也就是component注解实现的功能@service都能实现，而@service是对@component进一步拓展，被@service注解标注的类会被spring认定是业务逻辑层，里面有spring对业务逻辑层管理的一对逻辑。
```

##### SpringIOC(Inversion Of Control)-一种思想

###### 概念

Spring通过配置文件描述Bean以及Bean之间的依赖关系，利用Java语言的反射功能实例化Bean并建立Bean之间的依赖关系。Spring的IOC容器在完成这些工作的基础上，还提供了Bean实例缓存、生命周期管理、Bean实例代理、事件发布、资源装载等

###### Spring容器(HashMap)

![image-20220220224504802](C:\Users\Administrator\Desktop\interview\spring容器.png)

```
1. 读取配置文件获取bean的配置信息，添加到Spring容器的Bean定义注册表

2. 根据Bean定义的注册表实例化Bean

3. 将Bean实例放入Spring容器中，即Bean的缓存池

4. 应用程序从缓存池获取Bean
```

* **BeanDefinition**

* **BeanDefinitionRegistry**

  提供向IOC容器注册BeanDefinition对象的方法

* **ApplicationContext**

  ![image-20220226153219181](C:\Users\Administrator\Desktop\interview\ApplicationContext.png)

###### Spring Bean的作用域和生命周期

* 作用域

  ![image-20220220224753892](C:\Users\Administrator\Desktop\interview\bean作用域.png)

* 生命周期

  ![](C:\Users\Administrator\Desktop\interview\bean生命周期.png)

###### 依赖注入(DI)

* DI之前

  上层建筑依赖下层建筑：如果需要修改下层，每个层级都需要变动，那么对于整体功能影响大

* DI之后

  把底层类作为参数传递给上层类，实现上层对下层的"控制"，只需要底层类即可

* 注入方式

  * set注入
  * 构造器注入
  * 接口注入
  * 注解注入(@Autowired和@Resource)

###### 依赖查找(DL：废弃)

##### Spring AOP原理

###### 概念

AOP：面向切面编程

**切面Aspect**：通用化代功能代码的实现，用@Aspect标记通用类

业务功能代码和切面代码分开后，架构变得高内聚低耦合

* 如何将切面代码与业务代码合并

  **织入Weave**：确保功能完整性，切面最终需要被合并到业务中

  * 编译时织入：需要特殊的Java编译器，如AspectJ
  * 类加载时织入：需要特殊的Java编译器，如AspectJ和AspectWerkz
  * 运行时织入：Spring采用的方式，通过动态代理方式

  **Targer**：被织入Aspect的对象(业务类)

  **Join Point**：可以作为切入点的机会，所有方法都可以作为切入点

  **切点Pointcut**：通用代码合并到业务代码的位置，即Aspect实际被应用在Join Point，支持正则

  * "何时切入(**Advice**)"：类里的方法以及这个方法如何织入到目标方法的方式
    * Before 前置通知
    * AfterReturning 后置通知
    * AfterThrowing 异常通知
    * Around 环绕通知
    * After 最终通知

  

  



![image-20220220224958120](C:\Users\Administrator\Desktop\interview\aop概念.png)

###### 代理方式

​	具体由哪种方式实现根据AopProxyFactory和AdvisedSupport对象的配置决定

​	默认策略：若目标类是接口，则用JDKProxy实现；否则CGlib 

* JDK动态代理(只能为接口创建代理实例)

  核心：通过反射接收代理类，被代理类必须实现一个接口

  反射机制中重要的接口和类： InvocationHandler(Interface)、Proxy(Class)

  反射机制在生成类的过程中比较高效

* CGLib动态代理(以继承方式动态生成目标类的代理)

  核心：借助ASM实现

  ASM在生成类之后的执行过程中比较高效

  CGLib不能对声明为final的方法进行代理，因为CGLib原理是动态生成被代理类的子类。

### Mybatis

##### 一级缓存(sqlsession级别)

```
1.第一次发出查询SQL，SQL结果写入SQLSESSION的一级缓存中，缓存使用的数据结构是map
	key：mapperid+offset+limit+sql+入参
	value：用户信息
2.同一个sqlsession发出相同的sql，就从缓存中取出数据。如果两次中间出现commit操作(修改、删除、新增)本sqlsession中以及缓存区域全部清空，下次从缓存中查询不到，从DB查询写入缓存
```

##### 二级缓存(sqlsessionfactory或mapper级别：同一个命名空间)

```
1.mapper是以命名空间为单位创建缓存数据结构，结构是map
	key：mapperid+offset+limit+sql+入参
2.mybatis的二级缓存是通过CacheExecutor实现的。CacheExecutor是Executor的代理对象，所有的查询操作在CacheExecutor中都会先匹配缓存中是否存在，不存在查询DB
3.使用需要配置
	①全局配置中启用二级缓存
	②在对应mapper.xml配置cache节点
	③在对应的select查询节点添加useCache=true
4.返回的对象必须是序列化的
```

### 分布式事务

# 中间件

### Redis

##### 概念

###### 缓存击穿：key过期，造成并发访问DB

###### 缓存穿透：查询系统不存在的数据

###### 缓存雪崩：大量的key同时失效

##### 持久化

###### AOF(Append-Only-File：保存写状态)

```
1. 保存写状态
	1.1 记录下除了查询以外的所有变更数据库状态的指令
  	1.2 以append的形式追加保存到AOF文件中(增量)
2. redis.conf
	 appendonly no -> yes
     appendfsync everysec(每1s写入一次)|always(来一个指令则调用fsync一次)|no(由OS决定，一般是等到缓存区填满才写入)
  【注】fsync函数：将指定文件的内容强制从内核缓存刷新到磁盘，是一个"磁盘I/O操作"，速度很慢。
3. "日志重写"解决AOF文件大小不断增大的问题 - bfrewriteaof
	 3.1 调用fork()，创建一个子进程，对内存进行遍历，转换成redis的指令，序列化到一个新的AOF文件
     3.2 子进程把新的AOF写到一个临时文件里，不依赖原来的AOF文件
     3.3 主进程持续把新的变动同时写到内存和原来的AOF里
     3.4 主进程获取子进程重写AOF的完成信号，往新的AOF同步增量变动
     3.5 使用新的AOF文件替换掉旧的AOF文件
```

###### RDB(快照：保存某个时间点的全量数据快照)

```
1. redis.conf
	save 900 1 // 900s内有1条写入指令则触发1次RDB
   	save 300 10 // 300s有10条写入指令则触发1次RDB但变动数没有大于10则等到900s再去备份
   	save 60 10000
   	stop-writes-on-bgsave-error yes // 备份进程出错，停止主进程写入操作(保护数据持久化一致性)
   	rdbcompression yes // 备份需要将rdb压缩，建议为no，redis为CPU密集型服务器，开启影响cpu性能(save "" // 禁用rdb配置)
2. rdb文件生成的两个命令
	2.1 SAVE：阻塞redis的服务器进程，直到RDB文件被创建完毕(SAVE在主线程中保存快照，redis用主线程处理所有请求，会阻塞client的请求)
  	2.2 BGSAVE：Fork出一个子进程来创建RDB文件，不阻塞服务器进程
	 		多进程COW(copy on write)-写时复制
3. 自动化触发RDB持久化的方式
	3.1 根据redis.conf中的save m n定时触发(用的bgsave)
    3.2 主从复制时，主节点自动触发
    3.3 执行debug reload
    3.4 执行shutdown且没有开启aof持久化
4. 缺点
	4.1 内存数据量的全量同步，数据量大会由于I/O影响性能
  	4.2 可能会因为redis挂掉而丢失从当前至最近一次快照期间的数据
```

###### AOF与RDB的对比

```
RDB
	优点：全量数据快照，文件小，恢复快
  	缺点：无法保存最近一次快照之后的数据，rdb遍历整个内存，大块写磁盘会加重系统负载
AOF
	优点：可读性高，适合保存增量数据，数据不易丢失
  	缺点：文件体积大，恢复时间长，fsync是一个耗时的I/O操作，会降低redis的性能，增加系统IO负担
基于RDB和AOF的缺点，通常redis的主节点不进行持久化操作，该操作主要在从节点(备份节点，没有客户端请求的压力)进行。但如果出现网络分区，从节点连接不上主节点，可能会导致数据不一致的问题。
```

##### 分布式锁

```
1. 控制分布式系统或不同系统之间共同访问共享资源的一种锁的实现。
2. 原子操作：指不会被线程调度机制打断的操作，这种操作一旦开始，就会一直运行到结束，中间不会有任何线程切换。
3. 分布式锁需要解决的问题
	3.1 互斥性：任一时刻只有一个客户端获取锁
  	3.2 安全性：锁只能被持有者删除
  	3.3 死锁：获取锁的客户端宕机，没有释放锁，可以有其他方式释放锁，被其他客户端获取到锁
    3.4 容错：当部分节点宕机，客户端仍然可以获取锁和释放锁
4. redis实现分布式锁
	4.1 setnx key value：如果key不存在，则创建并赋值 - O(1)，成功：1；失败：0
  		....
  		del key
      如果中间出现异常，可能导致del没有调用，这就会导致死锁
  4.2 setnx key value 
  		expire key time // 设置过期时间
      ...
      del key
      Q1:由于setnx和expire是两条指令不是原子指令，如果出现机器断电或人为，导致expire得不到执行，导致死锁
  4.3 setnx key value [EX seconds] [PX milliseconds] [NX|XX]
  		EX seconds：设置键的过期时间为seconds秒
      PX seconds：设置键的过期时间为milliseconds毫秒
      NX：只在键不存在时，才对键进行设置操作
      XX：只在键已存在时，才对键进行设置操作
      成功：ok；失败：nil
      Q1:如果在加锁和释放锁之间的逻辑执行太长，超过过期时间，那么其他线程就可以获取锁，可能导致共享资源不能被独占，出现线程不安全情况
      Q2:大量key同时过期需要注意的问题
      A2:集中过期，由于清除大量的key耗时，会出现短暂的卡顿现象
      S2:在设置key的过期时间时，给每个key加上随机值
      4.3.1 可重入性(不推荐) 22-1.3.3
          * 指线程在持有锁的情况下再次请求加锁，如果一个锁支持同一个线程的多次加锁，那么这个锁就是可重入的。
          * redis的锁如果要支持可重入，需要对客户端的set方法进行包装，使用线程的ThreadLocal变量存储当前持有锁的计数。
      Q3:集群环境下，当主节点挂掉时，从节点取而代之，但是客户端在主节点申请的锁还没被从节点同步就过掉，那么当其他客户端申请加锁时，就到导致不安				 全情况产生。(仅在主从failover-故障转移的情况下发生，持续时间短，多数可以容忍。)
  4.4 RedLock算法
```

##### 同步机制

###### 主从同步

```
1.1 全量同步：主节点做bgsave，将后续修改操作记录到内存buffer中，完成后将redis文件全量同步到从节点
  1.1.1 slave发送sync命令到master
  1.1.2 master启用一个后台进程，将redis的数据快照保存到文件中
  1.1.3 master将保存数据快照期间接收到的写命令缓存起来
  1.1.4 master完成写文件操作后，将该文件发送给slave
  1.1.5 使用新的rdb文件替换旧的rdb文件
  1.1.6 master将这期间收集的增量写命令发送给slave端
1.2 增量同步：从节点接受完成后，将rdb文件加载到内存中，再通知主节点将期间修改的操作及增量数据同步到从节点
  1.2.1 master接收到用户的操作指令，判断是否需要传播到slave
  1.2.2 将操作记录追加到aof文件
  1.2.3 将操作传播到其他slave：①对齐主从库②往响应缓存写入指令
  1.2.4 将缓存中的数据发送给slave
  缺点：由于redis的复制内存buffer是一个定长的"环形"数组，如果数组内容满了，就会覆盖之前的内容(假设网络不好，从节点短时间无法和主节点进行同     	       步，当网路恢复时，从节点将无法通过指令流进行同步)
1.3 快照同步(全量同步+增量同步)
  1.3.1 在主节点进行bgsave，将当前内存的数据全部快照到磁盘文件中
  1.3.2 再将快照文件的内容全部传送到从节点
  1.3.3 从节点将快照文件接受完毕后，立即执行一次全量加载，加载之前先要将当前内存的数据清空
  1.3.4 加载完毕后通知主节点继续进行增量同步
  缺点：在整个快照同步的过程中，主节点的复制buffer还在往前移动，如果快照同步时间过长或复制buffer太小，导致同步期间的增量指令在复制buffer中被				 覆盖，就会导致同步完成后无法进行增量复制，再次发起快照同步，陷入快照同步的死循环。所以需要设置一个合适的复制buffer大小的参数，避免快照					同步的死循环
【注】弊端：不具备高可用，当master节点挂掉，redis将不能对外提供写入操作 
```

###### 哨兵

```
1. 解决主从同步master宕机后的主从切换问题
	1.1 监控：检查主从服务器是否运行正常
  	1.2 提醒：通过API向管理员或其他应用程序发送故障通知
  	1.3 自动故障迁移：主从切换
2. Sentinel无法保证消息不完全丢失，尽量保证少丢失，限制主从延迟过大
	min-slaves-to-write 1// 必须至少有一个从节点在进行正常复制，否则停止对外写服务
  	min-slaves-max-lag 10// 单位s，10s内没有收到从节点的反馈，就意味着从节点同步不正常
```

##### 集群

```
1. 一致性哈希算法
	1.1 对2^32取模，将哈希值空间组织成虚拟的圆环
  	1.2 将各个服务器进行哈希变换：可以选择服务器的IP或主机名作为关键字进行hash，确定服务器在哈希环的位置(将数据key使用相同的函数Hash计算出哈希			  值)
  	1.3 对数据使用同样的hash算法计算哈希值，沿环顺时针查找对应的服务器存储 
 	【注】当其中一个node宕机后，那么该节点的数据与下一个node之间的数据保存到下一个node，与上一个node之间的数据保存到逆时针最近的node(新增node同				理)
  	1.4 hash环的数据倾斜问题
  		Q:当服务器节点很少时，因为数据节点分布不均匀，导致数据倾斜(被缓存的对象大部分集中到某一个节点上)
      	A:引入虚拟节点，即对每一个节点计算多个哈希，在每个结果放置一个子服务器节点(虚拟节点，ip或主机名加编号计算)
 2. redis cluster所有数据划分为16384个槽位
 3. 容错
 		redis集群为每个主节点设置若干个从节点，当主节点发生故障，集群自动会从其中某个从节点提升为主节点，如果没有从节点，那么当主节点发生故障，集群		将处于完全不可用状态。
    	cluster-require-full-coverage// 允许部分节点发生故障，其他节点可以对外提供访问
 4. 网络抖动
 		cluster-node-timeout// 当某个及诶单持续timeout的时间失联时，才可以确定该节点出现故障，需要进行主从切换。(如果没有该选项，会导致频繁主从		 切换)
```

### ElasticSearch

##### 数据读写

###### ES写过程

```
1.ES会将document发送给coordinate node,节点根据document数据路由到指定的节点，该节点包含该primary shard
2.把文档存储写入到primary shard，如果设置了index.write.wait_for_active_shards=1,那么写完主节点，直接返回客户端，如果 index.write.wait_for_active_shards=all,那么必须要把所有的副本写入完成才返回客户端。
3.如果index.write.wait_for_active_shards=1，那么es会异步的把主分片的数据同步到副本分片上去。(在此期间，可能会出现读请求可能读取不到最新数据的情况)
```

###### ES读过程

```
1.客户端发送请求到任意一个 node，成为 coordinate node
2. coordinate node将请求的查询的条件，找到文档对应的分片和副本节点的地址
3.随机选择一个节点，一般是轮询，查询主节点，可能查询的是副本节点,然后将数据返回给coordinate node
4.coordinate node将数据返回给客户端。

由于可能存在primary shard的数据还没同步到 replica shard上的情况，所以客户端可能查询到旧的数据。
    方案1: 设置查询的时候只查主分片 preference=_primary ，详情见  
    方案2: 执行Update,Delete,Bulk等操作时，设备refresh策略，常见的有以下几种，
        refresh=true,更新数据之后，立刻对相关的分片(包括副本) 刷新。
        refresh=wait_for 这个参数表示，刷新不会立刻进行，而是等待一段时间才刷新，默认时间是1秒
        	index.refresh_interval
```

### RabbitMQ

# 处理的问题

#### JVM调优

###### 元空间

* 使用Orika进行bean拷贝，进行Bean注册，使用不当，导致元空间OOM

  ```java
  public class OOMTest {
      private static final MapperFactory MAPPER_FACTORY = new DefaultMapperFactory.Builder().build();
   
      public static void main(String[] args) {
          while(true) {
              Source source = new Source();
              source.setId(111);
              source.setPrice(123d);
              System.out.println(JSON.toJSONString(source));
              // 每调用一次就会在元空间注册生成一个class文件，
              MAPPER_FACTORY.classMap(Source.class, Target.class)
                      .field("price", "fee")
                      .byDefault()
                      .register();
              Target target2 = MAPPER_FACTORY.getMapperFacade().map(source, Target.class);
              System.out.println(JSON.toJSONString(target2));
          }
      } 
  }
  
  // 使用命令查看元空间，MC列表示当前元空间的使用情况，1000:1s打印一次
  jstat -gcmetacapacity pid 1000
      
  // 对象映射不需要每次都做，注册一遍即可
  ```

###### 栈

* 调用webservice调用服务，出现StackOverFlowError

  ```
  由于OOM是OutOfMemoryError,无法通过异常捕获,日志也没有打印,通过arthas的trace命令追踪方法查到位置
  原因：
  	DynamicClientFactory的createClient在创建是没有指定类加载器，都会使用当前线程的类加载器，当获取UrlClassLoader时会递归回调查询父类加载器，由于递归过深，导致StackOverFlowError
  ```







































